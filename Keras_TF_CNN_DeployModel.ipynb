{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Deep Learning Models via Azure ML CLI\n",
    "\n",
    "In this example, we show how to deploy the trained Keras (tensorflow) model as a web service through [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). The target machine learning problem is [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/c/cifar-10). Section [Model Training](#training) shows the same steps as the steps shown in this [High-level Keras (TF) Example](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/notebooks/Keras_TF_CNN.ipynb). By executing the scripts in this section, we train the Keras network and evaluate the trained model on testing data. In Section [Model Deployment](#deploy), we show the steps to save a Keras model, deploy the model through Azure CLI, and test the deployed web service. \n",
    "\n",
    "\n",
    "## Outline<a id=\"BackToTop\"></a>\n",
    "- [Prerequisite](#prerequisite)\n",
    "- [Model Training](#training)\n",
    "- [Model Deployment](#deploy)\n",
    "  - [Save the model](#save_model)\n",
    "  - [Write a scoring script](#score_script)\n",
    "  - [Test the trained model at local envionment](#test_local)\n",
    "  - [Deploy model as a Web Service](#deploy_model)\n",
    "  - [Test Web Service](#test_ws)\n",
    "  - [Debug Web Service](#debug_ws)\n",
    "  - [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite <a id=\"Prerequisite\"></a>\n",
    "\n",
    "- Azure subscription\n",
    "- Data Science Virtual Machine (DSVM) on Azure\n",
    "    \n",
    "    In this example, we use Deep Learning Virtual Machine - Linux OS, Standard [NC6 (6 vcpus, 56 GB memory) machine](https://azure.microsoft.com/en-us/blog/azure-n-series-preview-availability/) as the compute resource, where we train and deploy the model.  \n",
    "\n",
    "    The Deep Learning Virtual Machine (DLVM) is a specially configured variant of the Data Science Virtual Machine (DSVM) to make it easier to use GPU-based VM instances for training deep learning models. It is supported on Windows 2016, or the Ubuntu Data Science Virtual Machine and shares the same core VM images (and hence all the rich toolset) as the DSVM. We also provide end-to-end AI samples for image and text understanding. The deep learning virtual machine also makes the rich set of tools and samples on the DSVM more easily discoverable. In terms of the tooling, the Deep Learning Virtual Machine provides several popular deep learning frameworks, tools to acquire and pre-process image, textual data.\n",
    "    \n",
    "    We use following tools on this DSVM.\n",
    "    - Python 3\n",
    "    - Jupyter Notebook \n",
    "    - Azure CLI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Environment Configuration\n",
    "\n",
    "1. From your local machine ssh into the VM. In VM's CLI console, clone the repo to a desired location using below command. \n",
    "        $ git clone https://github.com/Azure/DeepLearningModelDeployment.git \n",
    "\n",
    "2. Launch Jupyter Server manually. It matters where and how the Jupyter server is launched. In order to make the remaining tutorial smooth, please follow below steps to launch Jupyter server. In VM's CLI console, (1) switch to use `py35` conda environment, and (2) launch Jupyter server from `py35` conda environment manually. Please follow below instructions to achieve it. \n",
    "\n",
    "    1) Change the conda environment \n",
    "        $ source activate py35 \n",
    "\n",
    "    2) Start the jupyter notebook from the command line\n",
    "        $ jupyter notebook --no-browser --ip=* \n",
    "   \n",
    "    3) In the output of above command, locate `http(s)://[all ip addresses on your system]:port_number/`. An example is, `https://[all ip addresses on your system]:9999/`. If it has `token` shown in part of this address, it is very likely you need to finish steps 7) - 10). If there is no URL in the output. Instead, you see: error message `No such notebook dir: \"/dsvm/Notebooks\"`, follow this page [Access Jupyter notebooks on Azure DSVM](http://yiyujia.blogspot.com/2018/05/access-jupyter-notebooks-on-azure-dsvm.html) to set c.NotebookApp.notebook_dir to be your home directory in `jupyter_notbook_config.py` file.\n",
    "\n",
    "    4) On the Azure portal create an inbound rule for port `port_number` (e.g. 9999 in above example), if not an inbound rule has been created for this port before. (To create an inbound rule: at the VM's overview page on Azure portl, click `Networking` and check if section `INBOUND PORT RULES` already has 9999 shown in PORT column. If not, click `Add inbound port rule`, then set `Destination port ranges` to be 9999, and modify `Name` to be \"Port_9999\". Finally click `Add`).\n",
    "    \n",
    "    5) On your local machine, open a web-browser and go to `http(s)://<VM IP address>:port_number/` as indicated in the above command output. When prompted for password, enter the password you have previously created. If you don't remember the password, finish steps 7) - 10). \n",
    "    \n",
    "    6) If you succesfully access `http(s)://<VM IP address>:port_number/` (ignore `Certificate error`), skip remaining steps. Otherwise, continue on below steps. \n",
    "    \n",
    "    7) In the concole, shut down the Jupyter server by typing `Ctrl+C`.\n",
    "    \n",
    "    8) Generate a jupyter configuration file.\n",
    "        $ jupyter notebook --generate-config \n",
    "    \n",
    "    9) Generate a jupyter password (create a password and enter it twice).\n",
    "        $ jupyter notebook password \n",
    "  \n",
    "    10) Start the jupyter notebook from the command line and go to step 5). \n",
    "        $ jupyter notebook --no-browser --ip=* \n",
    "\n",
    "By now, you should have the Jupyter server on and you can access the notebooks from the local copy of repo. Open the notebook `Keras_TF_CNN_DeployModel.ipynb` and make sure the kernel is set to be `Python [conda env: py35]`(To change a kernel, choose `kernel` - `Change kernel` in notebook menu).\n",
    "\n",
    "### Check configuration from Jupyter notebooks\n",
    "\n",
    "As a prerequisite, Azure CLI must be configured to make a set of \"az ml\" commands work for [model management](https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-cli-reference). In a notebook cell, type `az -h` and `az ml -h`. The output should look similar as below screenshots. This check ensures relevant commands works in the [Deploy model as a Web Service](#deploy_model) section. \n",
    "\n",
    "![azcheck](./imgs/azcheck.PNG)\n",
    "\n",
    "![azmlcheck](./imgs/azmlcheck.PNG)\n",
    "\n",
    "In case either check fails, please see this [Trouble Shooting](./common/Trouble_Shooting_Make_az_ml_ommands_run_in_notebooks.ipynb) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment following command and execute from your notebook\n",
    "#!az -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment following command and execute from your notebook\n",
    "#!az ml -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "import keras as K\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from common.params import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force one-gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Improvement\n",
    "# 1. Make sure channels-first (not last)\n",
    "K.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0]\n",
      "Keras:  2.1.4\n",
      "Numpy:  1.14.1\n",
      "Tensorflow:  1.6.0\n",
      "tensorflow\n",
      "channels_first\n",
      "GPU:  ['Tesla K80']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Keras: \", K.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Tensorflow: \", tensorflow.__version__)\n",
    "print(K.backend.backend())\n",
    "print(K.backend.image_data_format())\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symbol(n_classes=N_CLASSES):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                     input_shape=(3, 32, 32)))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(m, lr=LR, momentum=MOMENTUM):\n",
    "    m.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = K.optimizers.SGD(lr, momentum),\n",
    "        metrics = ['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Data does not exist. Downloading https://ikpublictutorial.blob.core.windows.net/deeplearningframeworks/cifar-10-python.tar.gz\n",
      "Extracting files...\n",
      "Preparing train set...\n",
      "Preparing test set...\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000, 10) (10000, 10)\n",
      "float32 float32 int32 int32\n",
      "CPU times: user 2.73 s, sys: 1.12 s, total: 3.85 s\n",
      "Wall time: 8.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(channel_first=True, one_hot=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 437 ms, sys: 2.63 s, total: 3.07 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "sym = create_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 359 µs, total: 28.9 ms\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialise model\n",
    "model = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 32, 32)        1400      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 32, 32)        22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 16, 16)       45100     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 16, 16)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,441,592\n",
      "Trainable params: 3,441,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.8471 - acc: 0.3300\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s 393us/step - loss: 1.4364 - acc: 0.4761\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 1.2250 - acc: 0.5598\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s 394us/step - loss: 1.0637 - acc: 0.6220\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 20s 394us/step - loss: 0.9402 - acc: 0.6680\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s 395us/step - loss: 0.8518 - acc: 0.6993\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 20s 394us/step - loss: 0.7687 - acc: 0.7296\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 20s 396us/step - loss: 0.7046 - acc: 0.7530\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 20s 393us/step - loss: 0.6471 - acc: 0.7700\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.5980 - acc: 0.7868\n",
      "CPU times: user 2min 34s, sys: 31.2 s, total: 3min 6s\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9de5867c88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Main training loop: 1m16s\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 677 ms, sys: 50.6 ms, total: 728 ms\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main evaluation loop\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7639\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", 1.*sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment <a id=\"deploy\"></a>\n",
    "\n",
    "- [Save the model](#save_model)\n",
    "- [Write a scoring script](#score_script)\n",
    "- [Test the trained model at local envionment](#test_local)\n",
    "- [Deploy model as a Web Service](#deploy_model)\n",
    "- [Test Web Service](#test_ws)\n",
    "- [Debug Web Service](#debug_ws)\n",
    "- [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model <a id=\"save_model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mylogin/notebooks/DeepLearningModelDeployment\n"
     ]
    }
   ],
   "source": [
    "#get the current working directory\n",
    "print(os.getcwd()) \n",
    "\n",
    "#list files in current working directory\n",
    "# os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.getcwd()\n",
    "o16n_path = os.path.join(local_path,'o16n')  \n",
    "model_path = os.path.join(o16n_path,'kerastfmodel')\n",
    "model_file_name = os.path.join(model_path,'kerastfmodel.h5')\n",
    "score_file_name = os.path.join(model_path, 'score.py')\n",
    "\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "if not os.path.exists(o16n_path):\n",
    "    os.makedirs(o16n_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mylogin/notebooks/DeepLearningModelDeployment/o16n/kerastfmodel\n",
      "/home/mylogin/notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "print(model_path)\n",
    "print(score_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a scoring script¶<a id=\"score_script\"></a>\n",
    "In order to create a web service, you will create a scoring script that will load the models, perform the prediction, and return the result. Azure ML uses init() and run() functions inside this scoring script for that purpose. The init() function initializes the web service and loads the saved model. The run() function uses the model and the input data to return a prediction which is executed on a scoring call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/mylogin/notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $score_file_name\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import keras as K\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model  \n",
    "\n",
    "    print(\"Executing init() method...\")\n",
    "    print(\"Python version: \" + str(sys.version) + \", keras version: \" + K.__version__)\n",
    "    # Load the model \n",
    "    model = K.models.load_model('kerastfmodel.h5')\n",
    "    return\n",
    "\n",
    "\n",
    "def run(inputString):\n",
    "    \n",
    "    responses = []\n",
    "    base64Dict = json.loads(inputString)\n",
    "\n",
    "    for k, v in base64Dict.items():\n",
    "        img_file_name, base64Img = k, v\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "    imageData = Image.open(img_buffer).convert(\"RGB\")\n",
    "\n",
    "    # Evaluate the model using the input data\n",
    "    img = ImageOps.fit(imageData, (32, 32), Image.ANTIALIAS)\n",
    "    img_conv = np.array(img) # shape: (32, 32, 3)\n",
    "    # Scale pixel intensity\n",
    "    x_test = img_conv / 255.0\n",
    "    # Reshape\n",
    "    x_test = np.moveaxis(x_test, -1, 0)\n",
    "    x_test = np.expand_dims(x_test, 0)  # shape (1, 3, 32, 32)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    # print(y_pred)\n",
    "    LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"fog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    resp = {img_file_name: str(LABELS[y_pred[0]])}\n",
    "\n",
    "    responses.append(resp)\n",
    "    return json.dumps(responses)\n",
    "    \n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    # input data\n",
    "    img_path = 'automobile8.png'\n",
    "    encoded = None\n",
    "    with open(img_path, 'rb') as file:\n",
    "      encoded = base64.b64encode(file.read())\n",
    "    img_dict = {img_path: encoded.decode('utf-8')}\n",
    "    body = json.dumps(img_dict)\n",
    "    resp = run(body)\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model at local envionment <a id=\"test_local\"></a>\n",
    "\n",
    "We test the trained model by supplying a test image to the model and checking the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F9DD81A1B38>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "test_img_name = os.path.join(local_path,'common/automobile8.png')\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mylogin/notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/automobile8.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to test the score.py, copy the test image to the same directory where score.py is\n",
    "import shutil\n",
    "shutil.copyfile(test_img_name, os.path.join(model_path, os.path.split(test_img_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score.py', 'kerastfmodel.h5', 'automobile8.png']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the image, scoring script and model are in the same folder.\n",
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score.py', 'kerastfmodel.h5', 'automobile8.png']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "os.chdir(model_path)\n",
    "#list files in current working directory\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Executing init() method...\n",
      "Python version: 3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0], keras version: 2.1.4\n",
      "2018-05-14 12:41:32.564982: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-05-14 12:41:32.660124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: f7e4:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 418.31MiB\n",
      "2018-05-14 12:41:32.660258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-05-14 12:41:32.989880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 155 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: f7e4:00:00.0, compute capability: 3.7)\n",
      "[{\"automobile8.png\": \"automobile\"}]\n"
     ]
    }
   ],
   "source": [
    "# run the scoring script to make a prediction for an input image \"automobile8.png\". \"automobile\" is the prediction result.\n",
    "!python score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as a Web Service <a id=\"deploy_model\"></a>\n",
    "\n",
    "In this section, we show the steps to deploy the previously trained model on [Azure Container Service (ACS)](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft.acs) via [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). \n",
    "\n",
    "During this section, following Azure resources will be created:\n",
    "    \n",
    "    - Resource group defined in variable YOUR_RESOURCE_GROUP\n",
    "        * Machine Learning Model Management\n",
    "        * cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "    - Resource group created during the cluster environment provision (YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\") \n",
    "        * Container registry\n",
    "        * Container service\n",
    "        * .... a bunch of other automatically provisoned resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mylogin/notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/conda_dependencies.yml'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy conda_dependencies.yml file into the directory model_path. This file is needed for model deployment.\n",
    "import shutil\n",
    "yml_file_name = os.path.join(local_path,'common/conda_dependencies.yml')\n",
    "shutil.copyfile(yml_file_name, os.path.join(model_path, os.path.split(yml_file_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conda_dependencies.yml', 'score.py', 'kerastfmodel.h5', 'automobile8.png']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list files in current working directory\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login your Azure account and set Azure subscription\n",
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing `!az login`, you will see following output message: To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code xxxxxxx to authenticate. Finish this login task in a browser and close the browser page.\n",
    "\n",
    "In the output of this command, you should see following information about your Azure subscription. Locate the \"name\" field and use it as the SUB_Name in the next cell. If you have more than one Azure subscritons, please choose one for this execercise. \n",
    "\n",
    "      {\n",
    "        \"cloudName\": \"AzureCloud\",\n",
    "        \"id\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n",
    "        \"isDefault\": true,\n",
    "        \"name\": \"Your Subscription Name\",\n",
    "        \"state\": \"Enabled\",\n",
    "        \"tenantId\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n",
    "        \"user\": {\n",
    "          \"name\": \"yourloginEmail@xxx.com\",\n",
    "          \"type\": \"user\"\n",
    "        }\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variable Names for Deployment\n",
    "SUB_Name = '\"Your Azure Subscription name\"' # Make sure you include double quote for your Azure subscription name\n",
    "LOCATION = 'Pick an Azure Region Here!! e.g. eastus2' # resource location\n",
    "DEPLOY_NAME = 'Pick a Deployment Name Here!!' # limite DEPLOY_NAME to 14 characters or less\n",
    "YOUR_RESOURCE_GROUP = DEPLOY_NAME + 'rg' \n",
    "MM_ACCOUNT = DEPLOY_NAME + 'mmacc'     \n",
    "CLUSTER_SERVICE_NAME = DEPLOY_NAME + 'clus' + 'srvc'\n",
    "CLUSTER_ENV_NAME = DEPLOY_NAME + 'clus' + 'env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s $SUB_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"yanzimgrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Create a resource group (optinal, only if you are about to create a new resource group)\n",
    "!az group create --l $LOCATION --name $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created_on\": \"2018-05-14T14:20:49.946446Z\",\r\n",
      "  \"description\": \"\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/providers/Microsoft.MachineLearningModelManagement/accounts/yanzimgmmacc\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/accounts/yanzimgmmacc/swagger.json?api-version=2017-09-01-preview\",\r\n",
      "  \"modified_on\": \"2018-05-14T14:20:49.946446Z\",\r\n",
      "  \"name\": \"yanzimgmmacc\",\r\n",
      "  \"resource_group\": \"yanzimgrg\",\r\n",
      "  \"sku\": {\r\n",
      "    \"capacity\": 1,\r\n",
      "    \"name\": \"S1\"\r\n",
      "  },\r\n",
      "  \"subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"tags\": {},\r\n",
      "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# execute following command to create a Machine Learning Model Management resource in the resource group\n",
    "!az ml account modelmanagement create -l $LOCATION -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az ml env setup --cluster -l  eastus2 -n  yanzimgclusenv -g  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Execute fllowing command to create the cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "# !az ml env setup --cluster -l $LOCATION -n $CLUSTER_ENV_NAME -g $YOUR_RESOURCE_GROUP\n",
    "print('az ml env setup --cluster -l ', LOCATION, '-n ', CLUSTER_ENV_NAME,'-g ', YOUR_RESOURCE_GROUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the above command in a new CLI console. (You need to ssh into the VM from your local machine again, as the Jupyter server is still running from previous openned console.) At the prompt, type 'n' for question \"Reuse storage and ACR (Y/n)?\" and 'Y' for question \"Continue with this subscription (Y/n)?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"Cluster Name\": \"yanzimgclusenv\",\r\n",
      "  \"Cluster Size\": 2,\r\n",
      "  \"Created On\": \"2018-05-14T14:25:50.8929999999999999Z\",\r\n",
      "  \"Location\": \"eastus2\",\r\n",
      "  \"Provisioning State\": \"Succeeded\",\r\n",
      "  \"Resource Group\": \"yanzimgrg\",\r\n",
      "  \"Subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# You can check the information on the environment with the following command. \n",
    "!az ml env show -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE] You will need to wait until \"Provisioning State\" is set to \"Succeeded\" to continue with the next steps. Check the state by running the cell again until you see Succeeded. The estimated waiting time is 15-20 minutes. When successfully provisioned, you will see a new resource group created in your Azure subscription with a bunch of resources in it. The name of this new resource group is YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". For example, my resource group name is \"yanzimgrg\" and the newly created resource group name is \"yanzimgrg-azureml-a0c61\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created_on\": \"2018-05-14T14:20:49.946446Z\",\r\n",
      "  \"description\": \"\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/providers/Microsoft.MachineLearningModelManagement/accounts/yanzimgmmacc\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/accounts/yanzimgmmacc/swagger.json?api-version=2017-09-01-preview\",\r\n",
      "  \"modified_on\": \"2018-05-14T14:20:49.946446Z\",\r\n",
      "  \"name\": \"yanzimgmmacc\",\r\n",
      "  \"resource_group\": \"yanzimgrg\",\r\n",
      "  \"sku\": {\r\n",
      "    \"capacity\": 1,\r\n",
      "    \"name\": \"S1\"\r\n",
      "  },\r\n",
      "  \"subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"tags\": {},\r\n",
      "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az ml account modelmanagement set -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubectl dashboard started for cluster at this endpoint: 127.0.0.1:39379/ui\r\n",
      "Compute set to yanzimgclusenv.\r\n"
     ]
    }
   ],
   "source": [
    "!az ml env set -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conda_dependencies.yml', 'score.py', 'kerastfmodel.h5', 'automobile8.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "# os.chdir(model_path)\n",
    "# list files in current working directory\n",
    "# Make sure current directory contains 'score.py', 'kerastfmodel.h5', and 'conda_dependencies.yml'\n",
    "\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kerastfmodel.h5\n",
      "Successfully registered model\n",
      "Id: a7137dc7277d45319a4ad268989e2c57\n",
      "More information: 'az ml model show -m a7137dc7277d45319a4ad268989e2c57'\n",
      "Creating new driver at /tmp/tmp2o5vbh7d.py\n",
      " score.py\n",
      "Successfully created manifest\n",
      "Id: c7cc51f3-5080-4394-b691-3b500b0edf05\n",
      "More information: 'az ml manifest show -i c7cc51f3-5080-4394-b691-3b500b0edf05'\n",
      "Creating image..............................................Done.\n",
      "Image ID: 475d667e-ec9e-4fb5-a2eb-a7a9087b2c26\n",
      "More details: 'az ml image show -i 475d667e-ec9e-4fb5-a2eb-a7a9087b2c26'\n",
      "Usage information: 'az ml image usage -i 475d667e-ec9e-4fb5-a2eb-a7a9087b2c26'\n",
      "Creating service...............................Done\n",
      "Service ID: yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2\n",
      "Usage: az ml service run realtime -i yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2 -d !! YOUR DATA HERE !!\n",
      "Additional usage information: 'az ml service usage realtime -i yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2'\n"
     ]
    }
   ],
   "source": [
    "# create web service - this step can take several minutes\n",
    "!az ml service create realtime --model-file kerastfmodel.h5 -f score.py -n $CLUSTER_SERVICE_NAME -r python -c conda_dependencies.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the web service is succesfully deployed, you should see a field \"Service ID\" from the output information. \n",
    "Take this information and put in CLUSTER_SERVICE_ID in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_SERVICE_ID = 'Your cluster service Id here!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Web Service <a id=\"test_ws\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring URL:\r\n",
      "    http://40.70.243.21/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Headers:\r\n",
      "    Content-Type: application/json\r\n",
      "    Authorization: Bearer <key>\r\n",
      "        (<key> can be found by running 'az ml service keys realtime -i yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2')\r\n",
      "\r\n",
      "Swagger URL:\r\n",
      "    http://40.70.243.21/api/v1/service/yanzimgclussrvc/swagger.json\r\n",
      "\r\n",
      "Sample CLI command:\r\n",
      "    az ml service run realtime -i yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2 -d !! YOUR DATA HERE !!\r\n",
      "\r\n",
      "Sample CURL call:\r\n",
      "    curl -X POST -H \"Content-Type:application/json\" -H \"Authorization:Bearer <key>\" --data !! YOUR DATA HERE !! http://40.70.243.21/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Get debug logs by calling:\r\n",
      "    az ml service logs realtime -i yanzimgclussrvc.yanzimgclusenv-12a73454.eastus2\r\n",
      "\r\n",
      "Get STDOUT/STDERR or Request/Response logs in App Insights:\r\n",
      "    https://analytics.applicationinsights.io/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/yanzimgrg-azureml-18575/components/mlcrpaid4868214320d#/discover/home?apptype=Other%20(preview)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Use following command to get the service URL and other details for calling the service endpoint. \n",
    "!az ml service usage realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the url from the field \"Scoring URL\" in above output\n",
    "url = 'Your Scoring URL Here!!'\n",
    "# e.g. url = 'http://40.70.243.21/api/v1/service/yanzimgclussrvc/score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrimaryKey: ol8GjkNVRh3OFnecnxXnD2WcaOwACjCZ\r\n",
      "SecondaryKey: 3jbNRcQzXM7tloijO87Ju9YXxDx0Y0ho\r\n"
     ]
    }
   ],
   "source": [
    "!az ml service keys realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the api key from the field \"PrimaryKey\" in above output\n",
    "api_key = 'Your Api Key Here!!'\n",
    "# e.g. api_key = '1efdf6b213ed4fd69f5bf47ae1a7fc60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7FAE5F299470>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the test image to predict on\n",
    "test_img_name = 'automobile8.png'\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile8.png\n"
     ]
    }
   ],
   "source": [
    "img_file_name = os.path.split(test_img_name)[1]\n",
    "print(img_file_name)\n",
    "# prepare a test image\n",
    "with open(test_img_name, 'rb') as file:\n",
    "  encoded = base64.b64encode(file.read())\n",
    "img_dict = {img_file_name: encoded.decode('utf-8')}\n",
    "body = json.dumps(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the web service end point\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "response = requests.post(url, headers=headers, data=body)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from above cell should be `<Response [200]>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"automobile8.png\": \"automobile\"}]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = json.loads(response.content.decode('ascii'))\n",
    "prediction # The firt part is the test image's name, and the second part is the predicted category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Web Service <a id=\"debug_ws\"></a>\n",
    "\n",
    "When the deployed web service does not behave as what you expected, you may want to debug it. You can add a couple \"print\" statement in score.py, deploy the web service, and get the log file by executing following command.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the log file wslog.txt will be generated in the current working directory\n",
    "!az ml service logs realtime -i $CLUSTER_SERVICE_ID > wslog.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE]: You need to delete the deployed web service before creating a new web service with the same name. Even if it shows that the web service deployment fails, you still need to delete it first. \n",
    "\n",
    "> In Azure portal, you can find the information about the deployed web service in the \"Machine Learning Model Management\" in YOUR_RESOURCE_GROUP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can delete a web service by executing following command. \n",
    "!az ml service delete realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up resources <a id=\"cleanup\"></a>\n",
    "\n",
    "*Note*: Please skip this section (not to clean up resources) if you want to continue on the second notebook.\n",
    "\n",
    "When you finish this example, you may want to avoid unnecessary cost by cleaning up the Azure resources you have provisioned. You need to delete two resource groups: YOUR_RESOURCE_GROUP and YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". The exact name for the second resource group can be found in your Azure portal. For example, my resource group name is YOUR_RESOURCE_GROUP = \"yanzimgrg\" and the other system created resource group name is \"yanzimgrg-azureml-a0c61\". I then need to execute following commands to delete these two resource groups.\n",
    "\n",
    "    az group delete -n yanzimgrg\n",
    "    az group delete -n yanzimgrg-azureml-a0c61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az group delete -n  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Delete resource group. Execute this command in the console. \n",
    "# Execute below command in CLI console, at the prompt type \"y\" (Q: Are you sure you want to perform this operation? (y/n):) \n",
    "# az group delete -n $YOUR_RESOURCE_GROUP\n",
    "print(\"az group delete -n \", YOUR_RESOURCE_GROUP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
