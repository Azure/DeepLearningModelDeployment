{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Keras (TF) Example\n",
    "\n",
    "In this example, we show how to deploy the trained Keras (tensorflow) model as a web service through [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). The target machine learning problem is [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/c/cifar-10). Section [Model Training](#training) shows the same steps as the steps shown in this [High-level Keras (TF) Example](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/notebooks/Keras_TF_CNN.ipynb). By executing the scripts in this section, we train the Keras network and evaluate the trained model on testing data. In Section [Model Deployment](#deploy), we show the steps to save a Keras model, deploy the model through Azure CLI, and test the deployed web service. \n",
    "\n",
    "\n",
    "## Outline<a id=\"BackToTop\"></a>\n",
    "- [Prerequisite](#prerequisite)\n",
    "- [Model Training](#training)\n",
    "- [Model Deployment](#deploy)\n",
    "  - [Save the model](#save_model)\n",
    "  - [Write a scoring script](#score_script)\n",
    "  - [Test the trained model at local envionment](#test_local)\n",
    "  - [Deploy model as a Web Service](#deploy_model)\n",
    "  - [Test Web Service](#test_ws)\n",
    "  - [Debug Web Service](#debug_ws)\n",
    "  - [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite <a id=\"Prerequisite\"></a>\n",
    "\n",
    "- Azure subscription\n",
    "- Data Science Virtual Machine (DSVM) on Azure\n",
    "    \n",
    "    In this example, we use Deep Learning Virtual Machine - Linux OS, Standard [NC6 (6 vcpus, 56 GB memory) machine](https://azure.microsoft.com/en-us/blog/azure-n-series-preview-availability/) as the compute resource, where we train and deploy the model.  \n",
    "\n",
    "    The Deep Learning Virtual Machine (DLVM) is a specially configured variant of the Data Science Virtual Machine (DSVM) to make it easier to use GPU-based VM instances for training deep learning models. It is supported on Windows 2016, or the Ubuntu Data Science Virtual Machine and shares the same core VM images (and hence all the rich toolset) as the DSVM. We also provide end-to-end AI samples for image and text understanding. The deep learning virtual machine also makes the rich set of tools and samples on the DSVM more easily discoverable. In terms of the tooling, the Deep Learning Virtual Machine provides several popular deep learning frameworks, tools to acquire and pre-process image, textual data.\n",
    "    \n",
    "    We use following tools on this DSVM.\n",
    "    - Python 3\n",
    "    - Jupyter Notebook \n",
    "    - Azure CLI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Environment Configuration\n",
    "\n",
    "1. Jupyter Server. It matters where and how the Jupyter server is launched. In order to make the remaining tutorial smooth, please follow below two steps to launch Jupyter server. In VM's bash console, (1) switch to use py35 conda env by exectuting `source activate py35`, and (2) launch Jupyter server from `py35` conda environment manually.\n",
    "\n",
    "2. As a prerequisite, Azure CLI must be configured to make a set of \"az ml\" commands work for [model management](https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-cli-reference). In a notebook cell, type `az -h` and `az ml -h`. The output should look similar as below screenshots. This check ensure relevant commands works in the [Deploy model as a Web Service](#deploy_model) section. \n",
    "\n",
    "![azcheck](./imgs/azcheck.PNG)\n",
    "\n",
    "![azmlcheck](./imgs/azmlcheck.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "import keras as K\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from common.params import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force one-gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Improvement\n",
    "# 1. Make sure channels-first (not last)\n",
    "K.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0]\n",
      "Keras:  2.1.4\n",
      "Numpy:  1.14.1\n",
      "Tensorflow:  1.6.0\n",
      "tensorflow\n",
      "channels_first\n",
      "GPU:  ['Tesla K80']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Keras: \", K.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Tensorflow: \", tensorflow.__version__)\n",
    "print(K.backend.backend())\n",
    "print(K.backend.image_data_format())\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symbol(n_classes=N_CLASSES):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                     input_shape=(3, 32, 32)))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(m, lr=LR, momentum=MOMENTUM):\n",
    "    m.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = K.optimizers.SGD(lr, momentum),\n",
    "        metrics = ['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Data does not exist. Downloading https://ikpublictutorial.blob.core.windows.net/deeplearningframeworks/cifar-10-python.tar.gz\n",
      "Extracting files...\n",
      "Preparing train set...\n",
      "Preparing test set...\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000, 10) (10000, 10)\n",
      "float32 float32 int32 int32\n",
      "CPU times: user 2.77 s, sys: 971 ms, total: 3.74 s\n",
      "Wall time: 8.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(channel_first=True, one_hot=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 431 ms, sys: 2.67 s, total: 3.1 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "sym = create_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 ms, sys: 36 µs, total: 28.2 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialise model\n",
    "model = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 32, 32)        1400      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 32, 32)        22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 16, 16)       45100     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 16, 16)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,441,592\n",
      "Trainable params: 3,441,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 36s 725us/step - loss: 1.8333 - acc: 0.3284\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 1.3486 - acc: 0.5118\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 1.1134 - acc: 0.6009\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 0.9449 - acc: 0.6667\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.8390 - acc: 0.7046\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.7546 - acc: 0.7338\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.6857 - acc: 0.7576\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.6282 - acc: 0.7786\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.5790 - acc: 0.7972\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.5245 - acc: 0.8150\n",
      "CPU times: user 2min 25s, sys: 31.6 s, total: 2min 56s\n",
      "Wall time: 3min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f532506aa20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Main training loop: 1m16s\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 557 ms, sys: 69.3 ms, total: 626 ms\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main evaluation loop\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7799\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", 1.*sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment <a id=\"deploy\"></a>\n",
    "\n",
    "- [Save the model](#save_model)\n",
    "- [Write a scoring script](#score_script)\n",
    "- [Test the trained model at local envionment](#test_local)\n",
    "- [Deploy model as a Web Service](#deploy_model)\n",
    "- [Test Web Service](#test_ws)\n",
    "- [Debug Web Service](#debug_ws)\n",
    "- [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model <a id=\"save_model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dsvm/Notebooks/DeepLearningModelDeployment\n"
     ]
    }
   ],
   "source": [
    "#get the current working directory\n",
    "print(os.getcwd()) \n",
    "\n",
    "#list files in current working directory\n",
    "# os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.getcwd()\n",
    "o16n_path = os.path.join(local_path,'o16n')  \n",
    "model_path = os.path.join(o16n_path,'kerastfmodel')\n",
    "model_file_name = os.path.join(model_path,'kerastfmodel.h5')\n",
    "score_file_name = os.path.join(model_path, 'score.py')\n",
    "\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "if not os.path.exists(o16n_path):\n",
    "    os.makedirs(o16n_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dsvm/Notebooks/DeepLearningModelDeployment/o16n/kerastfmodel\n",
      "/dsvm/Notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "print(model_path)\n",
    "print(score_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a scoring script¶<a id=\"score_script\"></a>\n",
    "In order to create a web service, you will create a scoring script that will load the models, perform the prediction, and return the result. Azure ML uses init() and run() functions inside this scoring script for that purpose. The init() function initializes the web service and loads the saved model. The run() function uses the model and the input data to return a prediction which is executed on a scoring call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /dsvm/Notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $score_file_name\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import keras as K\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model  \n",
    "\n",
    "    print(\"Executing init() method...\")\n",
    "    print(\"Python version: \" + str(sys.version) + \", keras version: \" + K.__version__)\n",
    "    # Load the model \n",
    "    model = K.models.load_model('kerastfmodel.h5')\n",
    "    return\n",
    "\n",
    "\n",
    "def run(inputString):\n",
    "    \n",
    "    responses = []\n",
    "    base64Dict = json.loads(inputString)\n",
    "\n",
    "    for k, v in base64Dict.items():\n",
    "        img_file_name, base64Img = k, v\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "    imageData = Image.open(img_buffer).convert(\"RGB\")\n",
    "\n",
    "    # Evaluate the model using the input data\n",
    "    img = ImageOps.fit(imageData, (32, 32), Image.ANTIALIAS)\n",
    "    img_conv = np.array(img) # shape: (32, 32, 3)\n",
    "    # Scale pixel intensity\n",
    "    x_test = img_conv / 255.0\n",
    "    # Reshape\n",
    "    x_test = np.moveaxis(x_test, -1, 0)\n",
    "    x_test = np.expand_dims(x_test, 0)  # shape (1, 3, 32, 32)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    # print(y_pred)\n",
    "    LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"fog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    resp = {img_file_name: str(LABELS[y_pred[0]])}\n",
    "\n",
    "    responses.append(resp)\n",
    "    return json.dumps(responses)\n",
    "    \n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    # input data\n",
    "    img_path = 'automobile8.png'\n",
    "    encoded = None\n",
    "    with open(img_path, 'rb') as file:\n",
    "      encoded = base64.b64encode(file.read())\n",
    "    img_dict = {img_path: encoded.decode('utf-8')}\n",
    "    body = json.dumps(img_dict)\n",
    "    resp = run(body)\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model at local envionment <a id=\"test_local\"></a>\n",
    "\n",
    "We test the trained model by supplying a test image to the model and checking the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5314391550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "test_img_name = os.path.join(local_path,'common/automobile8.png')\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dsvm/Notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/automobile8.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to test the score.py, copy the test image to the same directory where score.py is\n",
    "import shutil\n",
    "shutil.copyfile(test_img_name, os.path.join(model_path, os.path.split(test_img_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['automobile8.png', 'kerastfmodel.h5', 'score.py']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the image, scoring script and model are in the same folder.\n",
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['automobile8.png', 'kerastfmodel.h5', 'score.py']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "os.chdir(model_path)\n",
    "#list files in current working directory\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Executing init() method...\n",
      "Python version: 3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0], keras version: 2.1.4\n",
      "2018-05-04 15:06:21.696517: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-05-04 15:06:21.790625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: f7e4:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 418.31MiB\n",
      "2018-05-04 15:06:21.790690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-05-04 15:06:22.100959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 155 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: f7e4:00:00.0, compute capability: 3.7)\n",
      "[{\"automobile8.png\": \"automobile\"}]\n"
     ]
    }
   ],
   "source": [
    "!python score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as a Web Service <a id=\"deploy_model\"></a>\n",
    "\n",
    "In this section, we show the steps to deploy the previously trained model on [Azure Container Service (ACS)](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft.acs) via [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). \n",
    "\n",
    "During this section, following Azure resources will be created:\n",
    "    \n",
    "    - Resource group defined in variable YOUR_RESOURCE_GROUP\n",
    "        * Machine Learning Model Management\n",
    "        * cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "    - Resource group created during the cluster environment provision (YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\") \n",
    "        * Container registry\n",
    "        * Container service\n",
    "        * .... a bunch of other automatically provisoned resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dsvm/Notebooks/DeepLearningModelDeployment/o16n/kerastfmodel/conda_dependencies.yml'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy conda_dependencies.yml file into the directory model_path. \n",
    "import shutil\n",
    "yml_file_name = os.path.join(local_path,'common/conda_dependencies.yml')\n",
    "shutil.copyfile(yml_file_name, os.path.join(model_path, os.path.split(yml_file_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['automobile8.png', 'kerastfmodel.h5', 'conda_dependencies.yml', 'score.py']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list files in current working directory\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login your Azure account and set Azure subscription\n",
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing `!az login`, you will see following output message: To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code xxxxxxx to authenticate. Finish this login task in a browser and close the browser page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variable Names for Deployment\n",
    "SUB_Name = 'Your Azure Subscription name'  # Azure Subscription name\n",
    "LOCATION = 'Pick an Azure Region Here!! e.g. eastus2' # resource location\n",
    "DEPLOY_NAME = 'Pick a Deployment Name Here!!' \n",
    "YOUR_RESOURCE_GROUP = DEPLOY_NAME + 'rg' \n",
    "MM_ACCOUNT = DEPLOY_NAME + 'mmacc'     \n",
    "CLUSTER_SERVICE_NAME = DEPLOY_NAME + 'clus' + 'srvc'\n",
    "CLUSTER_ENV_NAME = DEPLOY_NAME + 'clus' + 'env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s $SUB_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"yanzimgrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Create a resource group\n",
    "!az group create --l $LOCATION --name $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute following command to create a Machine Learning Model Management resource in the resource group\n",
    "!az ml account modelmanagement create -l $LOCATION -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az ml env setup --cluster -l  eastus2 -n  yanzimgclusenv -g  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Execute fllowing command to create the cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "# Execute fllowing command in CLI, at the prompt type 'Y' (Q: Continue with this subscription (Y/n)?)\n",
    "# !az ml env setup --cluster -l $LOCATION -n $CLUSTER_ENV_NAME -g $YOUR_RESOURCE_GROUP\n",
    "print('az ml env setup --cluster -l ', LOCATION, '-n ', CLUSTER_ENV_NAME,'-g ', YOUR_RESOURCE_GROUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the information on the environment with the following command. \n",
    "!az ml env show -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE] You will need to wait until \"Provisioning State\" is set to \"Succeeded\" to continue with the next steps. Check the state by running the cell again until you see Succeeded. The estimated waiting time is 15-20 minutes. When successfully provisioned, you will see a new resource group created in your Azure subscription with a bunch of resources in it. The name of this new resource group is YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". For example, my resource group name is \"yanzimgrg\" and the newly created resource group name is \"yanzimgrg-azureml-a0c61\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created_on\": \"2018-04-04T13:18:49.76867Z\",\r\n",
      "  \"description\": \"\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/providers/Microsoft.MachineLearningModelManagement/accounts/yanzimgmmacc\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/accounts/yanzimgmmacc/swagger.json?api-version=2017-09-01-preview\",\r\n",
      "  \"modified_on\": \"2018-04-04T13:18:49.76867Z\",\r\n",
      "  \"name\": \"yanzimgmmacc\",\r\n",
      "  \"resource_group\": \"yanzimgrg\",\r\n",
      "  \"sku\": {\r\n",
      "    \"capacity\": 1,\r\n",
      "    \"name\": \"S1\"\r\n",
      "  },\r\n",
      "  \"subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"tags\": {},\r\n",
      "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az ml account modelmanagement set -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading client to /home/mylogin/bin/kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kubectl\u001b[0m\n",
      "\u001b[33mEnsure /home/mylogin/bin/kubectl is on the path to avoid seeing this message in the future.\u001b[0m\n",
      "Kubectl dashboard started for cluster at this endpoint: 127.0.0.1:37785/ui\n",
      "Compute set to yanzimgclusenv.\n"
     ]
    }
   ],
   "source": [
    "!az ml env set -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['automobile8.png', 'kerastfmodel.h5', 'conda_dependencies.yml', 'score.py']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "# os.chdir(model_path)\n",
    "# list files in current working directory\n",
    "# Make sure current directory contains 'score.py', 'kerastfmodel.h5', and 'conda_dependencies.yml'\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create web service - this step can take several minutes\n",
    "!az ml service create realtime --model-file kerastfmodel.h5 -f score.py -n $CLUSTER_SERVICE_NAME -r python -c conda_dependencies.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_SERVICE_ID = 'Your cluster service Id here!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Web Service <a id=\"test_ws\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring URL:\r\n",
      "    http://40.84.41.97/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Headers:\r\n",
      "    Content-Type: application/json\r\n",
      "    Authorization: Bearer <key>\r\n",
      "        (<key> can be found by running 'az ml service keys realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2')\r\n",
      "\r\n",
      "Swagger URL:\r\n",
      "    http://40.84.41.97/api/v1/service/yanzimgclussrvc/swagger.json\r\n",
      "\r\n",
      "Sample CLI command:\r\n",
      "    az ml service run realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2 -d !! YOUR DATA HERE !!\r\n",
      "\r\n",
      "Sample CURL call:\r\n",
      "    curl -X POST -H \"Content-Type:application/json\" -H \"Authorization:Bearer <key>\" --data !! YOUR DATA HERE !! http://40.84.41.97/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Get debug logs by calling:\r\n",
      "    az ml service logs realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2\r\n",
      "\r\n",
      "Get STDOUT/STDERR or Request/Response logs in App Insights:\r\n",
      "    https://analytics.applicationinsights.io/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/yanzimgrg-azureml-56b1e/components/mlcrpai311162063c98#/discover/home?apptype=Other%20(preview)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Use following command to get the service URL and other details for calling the service endpoint. \n",
    "!az ml service usage realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'Your Scoring URL Here!!'\n",
    "# e.g. url = 'http://40.84.41.97/api/v1/service/yanzimgclussrvc/score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrimaryKey: 1efdf6b213ed4fd69f5bf47ae1a7fc60\r\n",
      "SecondaryKey: 39780a70114a4acfb5f85894b1f02660\r\n"
     ]
    }
   ],
   "source": [
    "!az ml service keys realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'Your Api Key Here!!'\n",
    "# e.g. api_key = '1efdf6b213ed4fd69f5bf47ae1a7fc60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH3UlEQVR4nG1WaZMUxxHNzDq6+pp7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\nEQqH36NlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7FB2D4E53978>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the test image to predict on\n",
    "test_img_name = 'automobile8.png'\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile8.png\n"
     ]
    }
   ],
   "source": [
    "img_file_name = os.path.split(test_img_name)[1]\n",
    "print(img_file_name)\n",
    "# prepare a test image\n",
    "with open(test_img_name, 'rb') as file:\n",
    "  encoded = base64.b64encode(file.read())\n",
    "img_dict = {img_file_name: encoded.decode('utf-8')}\n",
    "body = json.dumps(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the web service end point\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "response = requests.post(url, headers=headers, data=body)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"automobile8.png\": \"automobile\"}]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = json.loads(response.content.decode('ascii'))\n",
    "prediction # The firt part is the test image's name, and the second part is the predicted category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Web Service <a id=\"debug_ws\"></a>\n",
    "\n",
    "When the deployed web service does not behave as what you expected, you may want to debug it. You can add a couple \"print\" statement in score.py, deploy the web service, and get the log file by executing following command.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the log file wslog.txt will be generated in the current working directory\n",
    "!az ml service logs realtime -i $CLUSTER_SERVICE_ID > wslog.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE]: You need to delete the deployed web service before creating a new web service with the same name. Even if it shows that the web service deployment fails, you still need to delete it first. \n",
    "\n",
    "> In Azure portal, you can find the information about the deployed web service in the \"Machine Learning Model Management\" in YOUR_RESOURCE_GROUP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service to delete yanzimgclussrvc.yanzimgclusenv-08525303.eastus2 not found.\r\n"
     ]
    }
   ],
   "source": [
    "# You can delete a web service by executing following command. \n",
    "!az ml service delete realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted service: amlcvtkobjws.yanzimgclusenv-08525303.eastus2\r\n"
     ]
    }
   ],
   "source": [
    "!az ml service delete realtime -i amlcvtkobjws.yanzimgclusenv-08525303.eastus2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up resources <a id=\"cleanup\"></a>\n",
    "\n",
    "When you finish this example, you may want to avoid unnecessary cost by cleaning up the Azure resources you have provisioned. You need to delete two resource groups: YOUR_RESOURCE_GROUP and YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". The exact name for the second resource group can be found in your Azure portal. For example, my resource group name is YOUR_RESOURCE_GROUP = \"yanzimgrg\" and the other system created resource group name is \"yanzimgrg-azureml-a0c61\". I then need to execute following commands to delete these two resource groups.\n",
    "\n",
    "    az group delete -n yanzimgrg\n",
    "    az group delete -n yanzimgrg-azureml-a0c61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az group delete -n  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Delete resource group. Execute this command in cmd console. \n",
    "# Execute below command in CLI console, at the prompt type \"y\" (Q: Are you sure you want to perform this operation? (y/n):) \n",
    "# az group delete -n $YOUR_RESOURCE_GROUP\n",
    "print(\"az group delete -n \", YOUR_RESOURCE_GROUP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
