{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Keras (TF) Example\n",
    "\n",
    "In this example, we show how to deploy the trained Keras (tensorflow) model as a web service through [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). The target machine learning problem is [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/c/cifar-10). Section [Model Training](#training) shows the same steps as the steps shown in this [High-level Keras (TF) Example](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/notebooks/Keras_TF_CNN.ipynb). By executing the scripts in this section, we train the Keras network and evaluate the trained model on testing data. In Section [Model Deployment](#deploy), we show the steps to save a Keras model, deploy the model through Azure CLI, and test the deplopyed web service. \n",
    "\n",
    "\n",
    "## Outline<a id=\"BackToTop\"></a>\n",
    "- [Prerequisite](#prerequisite)\n",
    "- [Model Training](#training)\n",
    "- [Model Deployment](#deploy)\n",
    "  - [Save the model](#save_model)\n",
    "  - [Write a scoring script](#score_script)\n",
    "  - [Test the trained model at local envionment](#test_local)\n",
    "  - [Deploy model as a Web Service](#deploy_model)\n",
    "  - [Test Web Service](#test_ws)\n",
    "  - [Debug Web Service](#debug_ws)\n",
    "  - [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite <a id=\"Prerequisite\"></a>\n",
    "\n",
    "- Azure subscription\n",
    "- Data Science Virtual Machine (DSVM) on Azure\n",
    "    \n",
    "    In this example, we use Deep Learning Virtual Machine - Linux OS, Standard [NC6 (6 vcpus, 56 GB memory) machine](https://azure.microsoft.com/en-us/blog/azure-n-series-preview-availability/) as the compute reource, where we train and deploy the model.  \n",
    "\n",
    "    The Deep Learning Virtual Machine (DLVM) is a specially configured variant of the Data Science Virtual Machine(DSVM) to make it easier to use GPU-based VM instances for training deep learning models. It is supported on Windows 2016, or the Ubuntu Data Science Virtual Machine and shares the same core VM images (and hence all the rich toolset) as the DSVM. We also provide end-to-end AI samples for image and text understanding. The deep learning virtual machine also makes the rich set of tools and samples on the DSVM more easily discoverable. In terms of the tooling, the Deep Learning Virtual Machine provides several popular deep learning frameworks, tools to acquire and pre-process image, textual data.\n",
    "    \n",
    "    We use following tools on this DSVM.\n",
    "    - Python 3\n",
    "    - Jupyter Notebook \n",
    "    - Azure CLI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE]: Open a command line console, exectue \"az login\" to log in your Azure account. You should keep this console open, as we need to use this it to execute some commands in addition to this notebook. \n",
    "\n",
    "> As a prerequisite, Azure CLI must be configured to make a set of \"az ml\" commands work for model management. Type \"az ml -h\" in the console. If it is not shown similiar as below screenshot, you probably need to re-configure Azure CLI.\n",
    "\n",
    "![azml](./imgs/azml.PNG)\n",
    "\n",
    "> You can execute following command in a command line console to create a separate conda environment and do a fresh install. The installed package versions should be exactly same as in the provided requirement file to make az ml work. \n",
    "\n",
    "   > 1. In a command line console, navigate to \"common/\" directory and make sure cli-requirments.txt file is in it.\n",
    "   > 2. Execute following commands in the console.\n",
    "Â \n",
    "        conda create --name az_ml_test python=3.5\n",
    "        activate az_ml_test\n",
    "        pip install -r cli-requirements.txt\n",
    "        pip install azure-cli-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "import keras as K\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from common.params import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force one-gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Improvement\n",
    "# 1. Make sure channels-first (not last)\n",
    "K.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Keras:  2.0.8\n",
      "Numpy:  1.13.1\n",
      "Tensorflow:  1.3.0\n",
      "tensorflow\n",
      "channels_first\n",
      "GPU:  ['Tesla K80']\n",
      "CUDA Version 8.0.61\n",
      "CuDNN Version  5.1.10\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Keras: \", K.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Tensorflow: \", tensorflow.__version__)\n",
    "print(K.backend.backend())\n",
    "print(K.backend.image_data_format())\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symbol(n_classes=N_CLASSES):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                     input_shape=(3, 32, 32)))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(m, lr=LR, momentum=MOMENTUM):\n",
    "    m.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = K.optimizers.SGD(lr, momentum),\n",
    "        metrics = ['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Preparing test set...\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000, 10) (10000, 10)\n",
      "float32 float32 int32 int32\n",
      "CPU times: user 896 ms, sys: 548 ms, total: 1.44 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(channel_first=True, one_hot=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "sym = create_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 0 ns, total: 28 ms\n",
      "Wall time: 25.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialise model\n",
    "model = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 32, 32)        1400      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 32, 32)        22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 16, 16)       45100     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 16, 16)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,441,592\n",
      "Trainable params: 3,441,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 56s - loss: 1.8018 - acc: 0.3429    - ETA: 5s - loss: 1.8327 - acc: 0.3 - ETA: 5s - loss: 1.8317 - a - ETA: 2s\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 54s - loss: 1.3816 - acc: 0.5000    \n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 54s - loss: 1.1594 - acc: 0.5834    \n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 55s - loss: 1.0084 - acc: 0.6421    \n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 55s - loss: 0.8831 - acc: 0.6873    \n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 56s - loss: 0.7941 - acc: 0.7192    \n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 56s - loss: 0.7169 - acc: 0.7488    \n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 57s - loss: 0.6565 - acc: 0.7689    \n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 58s - loss: 0.5938 - acc: 0.7896    \n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 57s - loss: 0.5526 - acc: 0.8050    \n",
      "CPU times: user 6min 24s, sys: 1min 18s, total: 7min 43s\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4600e031d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Main training loop: 1m16s\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 200 ms, total: 1.5 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main evaluation loop\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7776\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", 1.*sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment <a id=\"deploy\"></a>\n",
    "\n",
    "- [Save the model](#save_model)\n",
    "- [Write a scoring script](#score_script)\n",
    "- [Test the trained model at local envionment](#test_local)\n",
    "- [Deploy model as a Web Service](#deploy_model)\n",
    "- [Test Web Service](#test_ws)\n",
    "- [Debug Web Service](#debug_ws)\n",
    "- [Clean up resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model <a id=\"save_model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mylogin/DeepLearningFrameworks\n"
     ]
    }
   ],
   "source": [
    "#get the current working directory\n",
    "print(os.getcwd()) \n",
    "\n",
    "#list files in current working directory\n",
    "# os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.getcwd()\n",
    "o16n_path = os.path.join(local_path,'o16n')  \n",
    "model_path = os.path.join(o16n_path,'kerastfmodel')\n",
    "model_file_name = os.path.join(model_path,'kerastfmodel.h5')\n",
    "score_file_name = os.path.join(model_path, 'score.py')\n",
    "\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "if not os.path.exists(o16n_path):\n",
    "    os.makedirs(o16n_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mylogin/DeepLearningFrameworks/o16n/kerastfmodel\n",
      "/home/mylogin/DeepLearningFrameworks/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "print(model_path)\n",
    "print(score_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a scoring scriptÂ¶<a id=\"score_script\"></a>\n",
    "In order to create a web service, you will create a scoring script that will load the models, perform the prediction, and return the result. Azure ML uses init() and run() functions inside this scoring script for that purpose. The init() function initializes the web service and loads the saved model. The run() function uses the model and the input data to return a prediction which is executed on a scoring call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/mylogin/DeepLearningFrameworks/o16n/kerastfmodel/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $score_file_name\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import keras as K\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model  \n",
    "\n",
    "    print(\"Executing init() method...\")\n",
    "    print(\"Python version: \" + str(sys.version) + \", keras version: \" + K.__version__)\n",
    "    # Load the model \n",
    "    model = K.models.load_model('kerastfmodel.h5')\n",
    "    return\n",
    "\n",
    "\n",
    "def run(inputString):\n",
    "    \n",
    "    responses = []\n",
    "    base64Dict = json.loads(inputString)\n",
    "\n",
    "    for k, v in base64Dict.items():\n",
    "        img_file_name, base64Img = k, v\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "    imageData = Image.open(img_buffer).convert(\"RGB\")\n",
    "\n",
    "    # Evaluate the model using the input data\n",
    "    img = ImageOps.fit(imageData, (32, 32), Image.ANTIALIAS)\n",
    "    img_conv = np.array(img) # shape: (32, 32, 3)\n",
    "    # Scale pixel intensity\n",
    "    x_test = img_conv / 255.0\n",
    "    # Reshape\n",
    "    x_test = x_test.reshape(-1, 3, 32, 32) # shape (1, 3, 32, 32)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    # print(y_pred)\n",
    "    LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"fog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    resp = {img_file_name: str(LABELS[y_pred[0]])}\n",
    "\n",
    "    responses.append(resp)\n",
    "    return json.dumps(responses)\n",
    "    \n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    # input data\n",
    "    img_path = 'automobile8.png'\n",
    "    encoded = None\n",
    "    with open(img_path, 'rb') as file:\n",
    "      encoded = base64.b64encode(file.read())\n",
    "    img_dict = {img_path: encoded.decode('utf-8')}\n",
    "    body = json.dumps(img_dict)\n",
    "    resp = run(body)\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model at local envionment <a id=\"test_local\"></a>\n",
    "\n",
    "We test the trained model by supplying a test image to the model and checking the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH3UlEQVR4nG1WaZMUxxHNzDq6+pp7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\nEQqH36NlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7FD913FBE390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "test_img_name = os.path.join(local_path,'common/automobile8.png')\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mylogin/DeepLearningFrameworks/o16n/kerastfmodel/automobile10.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to test the score.py, copy the test image to the same directory where score.py is\n",
    "import shutil\n",
    "shutil.copyfile(test_img_name, os.path.join(model_path, os.path.split(test_img_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score.py', 'kerastfmodel.h5', 'automobile8.png', 'conda_dependencies.yml']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the image, scoring script and model are in the same folder.\n",
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test score.py:\n",
    "\n",
    "1. open a CLI console in your local envionment\n",
    "2. navigate to directory /o16n/kerastfmodel\n",
    "3. run following command:\n",
    "\n",
    "    python score.py\n",
    "    \n",
    "The sample output is shown in below screenshot. \n",
    "\n",
    " ![Expected Output](./imgs/localtest.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as a Web Service <a id=\"deploy_model\"></a>\n",
    "\n",
    "In this section, we show the steps to deploy the previously trained model on [Azure Container Service (ACS)](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft.acs) via [Azure CLI](https://azure.microsoft.com/en-us/blog/announcing-general-availability-of-vm-storage-and-network-azure-cli-2-0/). \n",
    "\n",
    "During this section, following Azure resources will be created:\n",
    "    \n",
    "    - Resource group defined in variable YOUR_RESOURCE_GROUP\n",
    "        * Machine Learning Model Management\n",
    "        * cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "    - Resource group created during the cluster environment provision (YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\") \n",
    "        * Container registry\n",
    "        * Container service\n",
    "        * .... a bunch of other automatically provisoned resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mylogin/DeepLearningFrameworks/o16n/kerastfmodel/conda_dependencies.yml'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy conda_dependencies.yml file into the directory model_path. \n",
    "import shutil\n",
    "yml_file_name = os.path.join(local_path,'common/conda_dependencies.yml')\n",
    "shutil.copyfile(yml_file_name, os.path.join(model_path, os.path.split(yml_file_name)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score.py', 'kerastfmodel.h5', 'automobile8.png', 'conda_dependencies.yml']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "os.chdir(model_path)\n",
    "#list files in current working directory\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variable Names for Deployment\n",
    "SUB_Name = 'Your Azure Subscription name'  # Azure Subscription name\n",
    "LOCATION = 'Pick an Azure Region Here!! e.g. eastus2' # resource location\n",
    "DEPLOY_NAME = 'Pick a Deployment Name Here!!' \n",
    "YOUR_RESOURCE_GROUP = DEPLOY_NAME + 'rg' \n",
    "MM_ACCOUNT = DEPLOY_NAME + 'mmacc'     \n",
    "CLUSTER_SERVICE_NAME = DEPLOY_NAME + 'clus' + 'srvc'\n",
    "CLUSTER_ENV_NAME = DEPLOY_NAME + 'clus' + 'env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"yanzimgrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Create a resource group\n",
    "!az group create --l $LOCATION --name $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{\n",
      "  \"created_on\": \"2018-04-04T13:18:49.76867Z\",\n",
      "  \"description\": \"\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/providers/Microsoft.MachineLearningModelManagement/accounts/yanzimgmmacc\",\n",
      "  \"location\": \"eastus2\",\n",
      "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/accounts/yanzimgmmacc/swagger.json?api-version=2017-09-01-preview\",\n",
      "  \"modified_on\": \"2018-04-04T13:18:49.76867Z\",\n",
      "  \"name\": \"yanzimgmmacc\",\n",
      "  \"resource_group\": \"yanzimgrg\",\n",
      "  \"sku\": {\n",
      "    \"capacity\": 1,\n",
      "    \"name\": \"S1\"\n",
      "  },\n",
      "  \"subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# execute following command to create a Machine Learning Model Management resource in the resource group\n",
    "!az ml account modelmanagement create -l $LOCATION -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az ml env setup --cluster -l  eastus2 -n  yanzimgclusenv -g  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Execute fllowing command to create the cluster environment (Microsoft.MachineLearningCompute/operationalizationClusters)\n",
    "# Execute fllowing command in CLI, at the prompt type 'Y' (Q: Continue with this subscription (Y/n)?)\n",
    "# !az ml env setup --cluster -l $LOCATION -n $CLUSTER_ENV_NAME -g $YOUR_RESOURCE_GROUP\n",
    "print('az ml env setup --cluster -l ', LOCATION, '-n ', CLUSTER_ENV_NAME,'-g ', YOUR_RESOURCE_GROUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"Cluster Name\": \"yanzimgclusenv\",\r\n",
      "  \"Cluster Size\": 2,\r\n",
      "  \"Created On\": \"2018-04-04T13:31:22.7979999999999999Z\",\r\n",
      "  \"Location\": \"eastus2\",\r\n",
      "  \"Provisioning State\": \"Succeeded\",\r\n",
      "  \"Resource Group\": \"yanzimgrg\",\r\n",
      "  \"Subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# You can check the information on the environment with the following command. \n",
    "!az ml env show -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE] You will need to wait until \"Provisioning State\" is set to \"Succeeded\" to continue with the next steps. Check the state by running the cell again untill you see Succeeded. The estimated waiting time is 15-20 minutes. When sucessfully provisioned, you will see a new resource group created in your Azure subscription with a bunch of resources in it. The name of this new resource group is YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". For example, my resource group name is \"yanzimgrg\" and the newly created resource group name is \"yanzimgrg-azureml-a0c61\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"created_on\": \"2018-04-04T13:18:49.76867Z\",\r\n",
      "  \"description\": \"\",\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/providers/Microsoft.MachineLearningModelManagement/accounts/yanzimgmmacc\",\r\n",
      "  \"location\": \"eastus2\",\r\n",
      "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/yanzimgrg/accounts/yanzimgmmacc/swagger.json?api-version=2017-09-01-preview\",\r\n",
      "  \"modified_on\": \"2018-04-04T13:18:49.76867Z\",\r\n",
      "  \"name\": \"yanzimgmmacc\",\r\n",
      "  \"resource_group\": \"yanzimgrg\",\r\n",
      "  \"sku\": {\r\n",
      "    \"capacity\": 1,\r\n",
      "    \"name\": \"S1\"\r\n",
      "  },\r\n",
      "  \"subscription\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"tags\": {},\r\n",
      "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az ml account modelmanagement set -n $MM_ACCOUNT -g $YOUR_RESOURCE_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubectl dashboard started for cluster at this endpoint: 127.0.0.1:34731/ui\r\n",
      "Compute set to yanzimgclusenv.\r\n"
     ]
    }
   ],
   "source": [
    "!az ml env set -g $YOUR_RESOURCE_GROUP -n $CLUSTER_ENV_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score.py', 'kerastfmodel.h5', 'automobile8.png', 'conda_dependencies.yml']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current working directory to model_path\n",
    "# os.chdir(model_path)\n",
    "# list files in current working directory\n",
    "# Make sure current directory contains 'score.py', 'kerastfmodel.h5', and 'conda_dependencies.yml'\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kerastfmodel.h5\n",
      "Successfully registered model\n",
      "Id: 7f43f55f091c41f4b5b6ff1ff26d9db8\n",
      "More information: 'az ml model show -m 7f43f55f091c41f4b5b6ff1ff26d9db8'\n",
      "Creating new driver at /tmp/tmpxkmzkwhl.py\n",
      " score.py\n",
      "Successfully created manifest\n",
      "Id: 1a966e1d-d403-4246-95ab-1b2bf7547bc2\n",
      "More information: 'az ml manifest show -i 1a966e1d-d403-4246-95ab-1b2bf7547bc2'\n",
      "Creating image..................................Done.\n",
      "Image ID: 45795324-b1c2-4650-8df9-e2458105c281\n",
      "More details: 'az ml image show -i 45795324-b1c2-4650-8df9-e2458105c281'\n",
      "Usage information: 'az ml image usage -i 45795324-b1c2-4650-8df9-e2458105c281'\n",
      "Creating service............................Done\n",
      "Service ID: yanzimgclussrvc.yanzimgclusenv-08525303.eastus2\n",
      "Usage: az ml service run realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2 -d !! YOUR DATA HERE !!\n",
      "Additional usage information: 'az ml service usage realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2'\n"
     ]
    }
   ],
   "source": [
    "# create web service\n",
    "!az ml service create realtime --model-file kerastfmodel.h5 -f score.py -n $CLUSTER_SERVICE_NAME -r python -c conda_dependencies.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTER_SERVICE_ID = 'Your cluster service Id here!!'\n",
    "CLUSTER_SERVICE_ID = 'yanzimgclussrvc.yanzimgclusenv-08525303.eastus2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Web Service <a id=\"test_ws\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring URL:\r\n",
      "    http://40.84.41.97/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Headers:\r\n",
      "    Content-Type: application/json\r\n",
      "    Authorization: Bearer <key>\r\n",
      "        (<key> can be found by running 'az ml service keys realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2')\r\n",
      "\r\n",
      "Swagger URL:\r\n",
      "    http://40.84.41.97/api/v1/service/yanzimgclussrvc/swagger.json\r\n",
      "\r\n",
      "Sample CLI command:\r\n",
      "    az ml service run realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2 -d !! YOUR DATA HERE !!\r\n",
      "\r\n",
      "Sample CURL call:\r\n",
      "    curl -X POST -H \"Content-Type:application/json\" -H \"Authorization:Bearer <key>\" --data !! YOUR DATA HERE !! http://40.84.41.97/api/v1/service/yanzimgclussrvc/score\r\n",
      "\r\n",
      "Get debug logs by calling:\r\n",
      "    az ml service logs realtime -i yanzimgclussrvc.yanzimgclusenv-08525303.eastus2\r\n",
      "\r\n",
      "Get STDOUT/STDERR or Request/Response logs in App Insights:\r\n",
      "    https://analytics.applicationinsights.io/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/yanzimgrg-azureml-56b1e/components/mlcrpai311162063c98#/discover/home?apptype=Other%20(preview)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Use following command to get the service URL and other details for calling the service endpoint. \n",
    "!az ml service usage realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'Your Scoring URL Here!!'\n",
    "# e.g. url = 'http://40.84.41.97/api/v1/service/yanzimgclussrvc/score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrimaryKey: 1efdf6b213ed4fd69f5bf47ae1a7fc60\r\n",
      "SecondaryKey: 39780a70114a4acfb5f85894b1f02660\r\n"
     ]
    }
   ],
   "source": [
    "!az ml service keys realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'Your Api Key Here!!'\n",
    "# e.g. api_key = '1efdf6b213ed4fd69f5bf47ae1a7fc60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH3UlEQVR4nG1WaZMUxxHNzDq6+pp7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\nEQqH36NlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7FB2D4E53978>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the test image to predict on\n",
    "test_img_name = 'automobile8.png'\n",
    "Image.open(test_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile8.png\n"
     ]
    }
   ],
   "source": [
    "img_file_name = os.path.split(test_img_name)[1]\n",
    "print(img_file_name)\n",
    "# prepare a test image\n",
    "with open(test_img_name, 'rb') as file:\n",
    "  encoded = base64.b64encode(file.read())\n",
    "img_dict = {img_file_name: encoded.decode('utf-8')}\n",
    "body = json.dumps(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the web service end point\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "response = requests.post(url, headers=headers, data=body)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"automobile8.png\": \"automobile\"}]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = json.loads(response.content.decode('ascii'))\n",
    "prediction # The firt part is the test image's name, and the second part is the predicted category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Web Service <a id=\"debug_ws\"></a>\n",
    "\n",
    "When the deployed web service does not behave as what you expected, you may want to debug it. You can add a couple \"print\" statement in score.py, deploy the web service, and get the log file by executing following command.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the log file wslog.txt will be generated in the current working directory\n",
    "!az ml service logs realtime -i $CLUSTER_SERVICE_ID > wslog.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [NOTE]: You need to delete the deployed web service before creating a new web service with the same name. Even if it shows that the web service deployment fails, you still need to delete it first. \n",
    "\n",
    "> In Azure portal, you can find the information about the deployed web service in the \"Machine Learning Model Management\" in YOUR_RESOURCE_GROUP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service to delete yanzimgclussrvc.yanzimgclusenv-08525303.eastus2 not found.\r\n"
     ]
    }
   ],
   "source": [
    "# You can delete a web service by executing following command. \n",
    "!az ml service delete realtime -i $CLUSTER_SERVICE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up resources <a id=\"cleanup\"></a>\n",
    "\n",
    "When you finish this example, you may want to avoid uncessary cost by cleanning up the Azure resources you have provisioned. You need to delete two resource groups: YOUR_RESOURCE_GROUP and YOUR_RESOURCE_GROUP plus\"-azureml-xxxxx\". The exact name for the second resource gorup can be found in your Azure portal. For example, my resource group name is YOUR_RESOURCE_GROUP = \"yanzimgrg\" and the other system created resource group name is \"yanzimgrg-azureml-a0c61\". I then need to execute following commands todelete these two resource groups. \n",
    "\n",
    "    az group delete -n yanzimgrg\n",
    "    az group delete -n yanzimgrg-azureml-a0c61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az group delete -n  yanzimgrg\n"
     ]
    }
   ],
   "source": [
    "# Delete resource group. Execute this command in cmd console. \n",
    "# Execute below command in CLI console, at the prompt type \"y\" (Q: Are you sure you want to perform this operation? (y/n):) \n",
    "# az group delete -n $YOUR_RESOURCE_GROUP\n",
    "print(\"az group delete -n \", YOUR_RESOURCE_GROUP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
